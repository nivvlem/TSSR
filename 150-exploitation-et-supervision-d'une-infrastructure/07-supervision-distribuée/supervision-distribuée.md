# Supervision distribuée avec Centreon
## 🧩 Principes de la supervision distribuée

- Architecture recommandée pour :
    - **Gros environnements** (plusieurs centaines d’hôtes)
    - **Sites distants** avec bande passante limitée
- Composants :
    - **Centreon Central** : interface web, base de données, moteur central (Engine), Broker principal
    - **Centreon Poller(s)** : serveur distant avec moteur de supervision (Engine) + Broker (module uniquement)
- Communication entre Central et Pollers :
    - Utilise **SSH** ou **ZMQ** (ZeroMQ)
    - Nécessite **échange de clés SSH** entre Central et Pollers

---

## 🔄 Rôle des serveurs dans une architecture distribuée

### Serveur Central

- Contient :
    - **Centreon Web** (interface)
    - **Centreon Broker Database** (vers base MariaDB ou PostgreSQL)
    - **Base de données RRD** (graphes)
    - Service **Gorgone** : transfert de config vers les pollers

### Serveurs Pollers (Satellites)

- Composants installés :
    - **Centreon Engine** : moteur de supervision
    - **Centreon Broker Module** : collecte les résultats des checks
- Fonctionnent **de manière autonome** :
    - Stockent les données temporairement si le Central est indisponible
    - Les synchronisent ensuite à la reconnexion

---

## 🛠️ Configuration d’un poller dans Centreon

1. Depuis **Centreon Web > Configuration > Pollers**
2. Ajouter un nouveau poller :
    - Nom explicite (ex : `Poller_Nagoya`)
    - IP interne accessible depuis Central
    - Définir les options SSH ou ZMQ
3. Attribuer les hôtes au bon poller via leur fiche ou modèle d’hôte
4. **Générer la configuration** depuis l’interface (comme pour Central)
5. Centreon **Gorgone** se charge de déployer les fichiers sur le poller distant

---

## 🧬 Résilience et indépendance des pollers

- Chaque poller peut continuer à :
    - Lancer ses propres checks (Engine local)
    - Stocker les résultats (en cache)
    - Reprendre la synchronisation dès que la liaison avec le Central est rétablie
- Le poller n’a pas besoin d’interface web ni de base SQL complète
- En cas de **perte réseau**, pas de perte de supervision locale

---

## 📜 Historique technique : de NDOUtils à Centreon Broker

|Composant|Fonction|Remplacé par|
|---|---|---|
|Nagios|Moteur de supervision|Centreon Engine|
|NDOUtils|Écriture base SQL|Centreon Broker|
|NDOMOD|Plugin Nagios → NDO|centreon-broker-module|
|NDO2DB|Récepteur TCP pour SQL|centreon-broker-database|

---

## ✅ À retenir pour les révisions

- La supervision distribuée repose sur des **pollers autonomes** déployés sur des sites distants ou pour répartir la charge
- Le **Central pilote l’ensemble** via l’interface et Gorgone
- **Centreon Broker** est le cœur de la transmission : module local → base centrale
- En cas de coupure, les **pollers tamponnent les données** et les synchronisent ensuite

---

## 📌 Bonnes pratiques professionnelles

- Bien **nommer les pollers** et leur associer un sous-réseau ou un site
- **Tester la clé SSH** entre Central et chaque poller (`ssh poller_user@poller_ip`)
- Documenter les **affectations d’hôtes par poller**
- Vérifier la bonne réception des données par le Broker via les logs
- Anticiper les **plans de reprise** en cas de perte du Central